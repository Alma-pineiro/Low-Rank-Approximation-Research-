{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e5f9121",
   "metadata": {},
   "source": [
    "In this notebook, we can see the beginning of the low-rank multiplication algorithm. We perform SVD on matrix A and then multiply the U, Σ, and Vᵀ matrices by matrix B. It’s important to note that, in this notebook, we are not taking into consideration the rank to which we want to reduce the matrix.\n",
    "\n",
    "The order of the multiplication is: final result = (U(Σ(Vᵀ(matrix_B))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "001ff505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Direct A @ B:\n",
      "[[34 30 21]\n",
      " [ 5 22 18]\n",
      " [21 23 36]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# First we are going to multiply matrix A and matrix B without either of them being reduced by SVD\n",
    "\n",
    "matrix_A = np.array([[1, 6, 4, 5],\n",
    "                     [2, -1, 0, 2],\n",
    "                     [4, 3, -2, 3]])\n",
    "\n",
    "matrix_B = np.array([[2, 5, 3],\n",
    "                     [3, -2, 0],\n",
    "                     [1, 3, -3],\n",
    "                     [2, 5, 6]])\n",
    "\n",
    "# Direct matrix multiplication\n",
    "direct_result = matrix_A @ matrix_B\n",
    "print(\"Direct A @ B:\", direct_result, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44e6b180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix U:\n",
      "[[ 0.87319638  0.48205415 -0.07177664]\n",
      " [ 0.1219709  -0.35873414 -0.92543661]\n",
      " [ 0.47185928 -0.79933323  0.37204193]]\n",
      "Matrix Σ:\n",
      "[[9.72158252 0.         0.        ]\n",
      " [0.         5.04456835 0.        ]\n",
      " [0.         0.         2.24569887]]\n",
      "Matrix V^T:\n",
      "[[ 0.30906237  0.67198784  0.262207    0.61980666]\n",
      " [-0.68048381  0.16910452  0.69914466 -0.13979338]\n",
      " [-0.19347301  0.71732796 -0.45918463 -0.48698898]]\n",
      "Final Result of LRM:\n",
      "[[34. 30. 21.]\n",
      " [ 5. 22. 18.]\n",
      " [21. 23. 36.]]\n",
      "Percentage Error between direct multiplication and LRM: 0.000000%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def LRM(matrix_A, matrix_B):\n",
    "    # SVD decomposition\n",
    "    U, S, VT = np.linalg.svd(matrix_A, full_matrices=False)\n",
    "    Sigma = np.diag(S)\n",
    "\n",
    "    print(\"Matrix U:\", U, sep=\"\\n\")\n",
    "    print(\"Matrix Σ:\", Sigma, sep=\"\\n\")\n",
    "    print(\"Matrix V^T:\", VT, sep=\"\\n\")\n",
    "\n",
    "    # Step 1: Multiply V^T and B first\n",
    "    step1 = VT @ matrix_B  # (3x4) @ (4x3) -> (3x3)\n",
    "\n",
    "    # Step 2: Scale each row of step1 by Sigma[i, i]\n",
    "    total = np.zeros_like(step1)\n",
    "    for i in range(Sigma.shape[0]):\n",
    "        total[i, :] = Sigma[i, i] * step1[i, :]\n",
    "\n",
    "    # Step 3: Multiply by U\n",
    "    final_result = U @ total\n",
    "    print(\"Final Result of LRM:\", final_result, sep=\"\\n\")\n",
    "    return final_result\n",
    "\n",
    "final_result = LRM(matrix_A, matrix_B)\n",
    "\n",
    "\n",
    "# Calculate percentage error\n",
    "error_percentage = (np.linalg.norm(direct_result - final_result, 'fro') / np.linalg.norm(direct_result, 'fro')) * 100\n",
    "print(f\"Percentage Error between direct multiplication and LRM: {error_percentage:.6f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
